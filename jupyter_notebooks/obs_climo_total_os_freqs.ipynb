{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e297bbf1-29dc-4aca-8a7c-11e955bdeb39",
   "metadata": {},
   "source": [
    "# Total OS frequencies (over the entire region/time period)\n",
    "This is summing the appropriate bins in the Tb-cpT histograms (below dashed and solid lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebd19bc-ea27-47b9-908f-cd326116ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5f4139-d870-4c35-b700-2eb17566ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/b/b380887/cold-point-overshoot/plots/obs_paper/tb_cp_hists/\"\n",
    "pickle_dir = \"/home/b/b380887/cold-point-overshoot/pickle_files/climo_tb_cp_hists//\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3acdc572-dea3-4a69-97aa-9277771b8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"DJF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31828656-a991-414d-927e-ae3a6ee74c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-2010\n"
     ]
    }
   ],
   "source": [
    "if season == \"DJF\":\n",
    "    region_list = [\"AMZ\", \"ECP\", \"IOS\", \"SPC\"]\n",
    "    year_list = [2007, 2008, 2009, 2010]\n",
    "    offset_dict = {\n",
    "        \"AMZ\": 9,\n",
    "        \"SPC\": 10,\n",
    "        \"IOS\": 9,\n",
    "        \"ECP\": 10\n",
    "    }\n",
    "\n",
    "elif season == \"JJA\":\n",
    "    region_list = [\"AFR\", \"ECP\", \"WPC\", \"IOE\"]\n",
    "    year_list = [2007, 2008, 2009, 2010] \n",
    "    offset_dict = {\n",
    "        \"AFR\": 10,\n",
    "        \"WPC\": 11,\n",
    "        \"IOE\": 8,\n",
    "        \"ECP\": 8\n",
    "    }\n",
    "    \n",
    "file_path = \"/work/bb1153/b380887/big_obs_climo/{s}/\".format(s=season)\n",
    "\n",
    "years_sorted = list(sorted(year_list))\n",
    "years_str = str(years_sorted[0]) + \"-\" + str(years_sorted[-1])\n",
    "print(years_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095bef9a-2f26-458b-8c4f-911a49b62a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_region_dict = {}\n",
    "\n",
    "for region in region_list:\n",
    "    hist_computed_list = [[]]*len(year_list)\n",
    "    nan_len_list = [[]]*len(year_list)\n",
    "\n",
    "    for i, year in enumerate(year_list):\n",
    "        file_to_open = pickle_dir + \"Tb-cpT_hist_dict_{s}{y}_{r}.pickle\".format(s=season, y=year, r=region)\n",
    "        with open(file_to_open, \"rb\") as handle:\n",
    "            hist_dict_yr = pickle.load(handle)\n",
    "        hist_computed_list[i] = hist_dict_yr[\"hist_computed\"]\n",
    "        nan_len_list[i] = hist_dict_yr[\"nan_len\"]\n",
    "\n",
    "    # sum across years\n",
    "    nan_len = sum(nan_len_list)\n",
    "    hist_computed = np.sum(hist_computed_list, axis=0)\n",
    "\n",
    "    # take bins & edges from the last dict in list\n",
    "    hist_dict = {\n",
    "        \"hist_computed\": hist_computed, \n",
    "        \"xedges\": hist_dict_yr[\"xedges\"], \n",
    "        \"yedges\": hist_dict_yr[\"yedges\"], \n",
    "        \"tb_bins\": hist_dict_yr[\"tb_bins\"], \n",
    "        \"cpT_bins\": hist_dict_yr[\"cpT_bins\"],\n",
    "        \"nan_len\": nan_len,\n",
    "    }\n",
    "\n",
    "    hist_region_dict[region] = hist_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960e8f0e-c00f-4169-a040-05aed3cdc238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_total_os_freq(hist_dict, offset, region):\n",
    "    \"\"\" Get counts and frequencies of Tb < cold point and threshold\n",
    "    \"\"\"\n",
    "    hist = hist_dict[\"hist_computed\"]\n",
    "    tb_edges = hist_dict[\"yedges\"]\n",
    "    cpT_edges = hist_dict[\"xedges\"]\n",
    "    xbin_means, ybin_means = (cpT_edges[:-1]+cpT_edges[1:])/2, (tb_edges[:-1]+tb_edges[1:])/2\n",
    "    \n",
    "    da = xr.DataArray(hist_dict[\"hist_computed\"],\n",
    "             dims=[\"cpT\", \"tb\"], \n",
    "             coords={\"cpT\": xbin_means, \"tb\": ybin_means},\n",
    "                  attrs={\"region\": region}\n",
    "            )\n",
    "    \n",
    "    count_below_thresh = np.nansum(da.where(da.tb < (da.cpT+offset)).values)\n",
    "    count_below_cp = np.nansum(da.where(da.tb < da.cpT).values)\n",
    "    \n",
    "    # nan_len is tb count, not the count on this histogram;\n",
    "    # it was used to normalize the histogram in the plots, but here we use the\n",
    "    # sum of the total histogram counts\n",
    "    freq_below_thresh = count_below_thresh / da.sum().values\n",
    "    freq_below_cp = count_below_cp / da.sum().values\n",
    "    \n",
    "    out_dict = {\n",
    "        \"region\": region,\n",
    "        \"offset\": offset,\n",
    "        \"count_below_thresh\": count_below_thresh,\n",
    "        \"count_below_cp\": count_below_cp,\n",
    "        \"freq_below_thresh\": freq_below_thresh,\n",
    "        \"freq_below_cp\": freq_below_cp,\n",
    "        \"thresh_def\": \"cold point bin mean + offset\"\n",
    "    }\n",
    "\n",
    "    return out_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7539ac9-640f-4af1-9ae8-1661b4050f2e",
   "metadata": {},
   "source": [
    "### Show the frequencies and save those dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674119a7-a013-4fc2-b4ca-86baa9ded2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZ: 0.0078%\n",
      "ECP: 0.0002%\n",
      "IOS: 0.0038%\n",
      "SPC: 0.0065%\n"
     ]
    }
   ],
   "source": [
    "# DJF\n",
    "out_dict_djf = {}\n",
    "for region in region_list:\n",
    "    out_dict = get_total_os_freq(hist_region_dict[region], offset_dict[region], region)\n",
    "    out_dict_djf[region] = out_dict\n",
    "    freq_thresh = out_dict[\"freq_below_thresh\"]*100.\n",
    "    freq_cp = out_dict[\"freq_below_cp\"]*100.\n",
    "\n",
    "    # print(\"{r}: {t:.3f}%, {c:.4f}%\".format(t=freq_thresh, c=freq_cp, r=region))\n",
    "    print(\"{r}: {c}%\".format(c=np.round(freq_cp, 4), r=region))\n",
    "\n",
    "    out_file = pickle_dir + \"total_os_freq_dict_{s}{y}_{r}.pickle\".format(s=season, y=years_str, r=region)\n",
    "    # with open(out_file, \"wb\") as handle:\n",
    "    #     pickle.dump(out_dict, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74369294-186f-42e1-9d02-ee8ed0ad2e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFR: 0.024%\n",
      "ECP: 0.002%\n",
      "WPC: 0.015%\n",
      "IOE: 0.004%\n"
     ]
    }
   ],
   "source": [
    "# JJA\n",
    "out_dict_jja = {}\n",
    "for region in region_list:\n",
    "    out_dict = get_total_os_freq(hist_region_dict[region], offset_dict[region], region)\n",
    "    out_dict_jja[region] = out_dict\n",
    "    freq_thresh = out_dict[\"freq_below_thresh\"]*100.\n",
    "    freq_cp = out_dict[\"freq_below_cp\"]*100.\n",
    "\n",
    "    # print(\"{r}: {t:.3f}%, {c:.4f}%\".format(t=freq_thresh, c=freq_cp, r=region))\n",
    "    print(\"{r}: {c}%\".format(c=np.round(freq_cp, 3), r=region))\n",
    "\n",
    "    out_file = pickle_dir + \"total_os_freq_dict_{s}{y}_{r}.pickle\".format(s=season, y=years_str, r=region)\n",
    "    # with open(out_file, \"wb\") as handle:\n",
    "    #     pickle.dump(out_dict, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a7b5bd4-f366-400a-b79a-83a56f763316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_two_regions(r1, r2, out_dict, count=False):\n",
    "    if count:\n",
    "        print(out_dict[r1][\"count_below_cp\"] / out_dict[r2][\"count_below_cp\"])\n",
    "    else:\n",
    "        print(out_dict[r1][\"freq_below_cp\"] / out_dict[r2][\"freq_below_cp\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4bd1722c-0249-4bfc-a0f2-4af27f453dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.207010434938332\n",
      "2.0739934835273703\n",
      "36.628570606792344\n",
      "1.7182896050383638\n"
     ]
    }
   ],
   "source": [
    "compare_two_regions(\"AMZ\", \"SPC\", out_dict_djf)\n",
    "compare_two_regions(\"AMZ\", \"IOS\", out_dict_djf)\n",
    "compare_two_regions(\"AMZ\", \"ECP\", out_dict_djf)\n",
    "compare_two_regions(\"SPC\", \"IOS\", out_dict_djf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3daa45a3-49b1-4c24-a9f1-5f1cfa07d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.579406569052873\n",
      "6.371141620047548\n",
      "11.214958658414067\n",
      "4.0338831969453866\n"
     ]
    }
   ],
   "source": [
    "compare_two_regions(\"AFR\", \"WPC\", out_dict_jja)\n",
    "compare_two_regions(\"AFR\", \"IOE\", out_dict_jja)\n",
    "compare_two_regions(\"AFR\", \"ECP\", out_dict_jja)\n",
    "compare_two_regions(\"WPC\", \"IOE\", out_dict_jja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bf916-ecb8-46f4-bf28-c4a41b93d705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2env",
   "language": "python",
   "name": "d2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
